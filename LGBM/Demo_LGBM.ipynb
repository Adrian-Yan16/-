{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "835bb297-fc85-47a2-8552-452b930fa89a"
   },
   "outputs": [],
   "source": [
    "# 天池新闻文本分类比赛\n",
    "# 初始baseline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "from threading import Thread\n",
    "\n",
    "data_path = \"./download/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "54e62ad7-ddbf-4203-9be7-e24b419395fc"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG,#控制台打印的日志级别\n",
    "                    filename='LGBM.log',\n",
    "                    filemode='a',##模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志\n",
    "                    #a是追加模式，默认如果不写的话，就是追加模式\n",
    "                    format=\n",
    "                    '%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'\n",
    "                    #日志格式\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "ce4ccaa6-5953-4d88-a834-bfa34906cdde"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path + 'train_set.csv',sep='\\t',nrows=None)\n",
    "test_df = pd.read_csv(data_path + 'test_a.csv',sep='\\t',nrows=None)\n",
    "# test_b_df = pd.read_csv(data_path + 'test_b.csv',sep='\\t',nrows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "4a25fde8-e992-4f97-a519-8714cb9675da"
   },
   "outputs": [],
   "source": [
    "def define_tfidf(ngram,max_feature):\n",
    "    return TfidfVectorizer(\n",
    "        sublinear_tf = True,\n",
    "        strip_accents = 'unicode',\n",
    "        analyzer = 'word',\n",
    "        token_pattern = r'\\w{1,}',\n",
    "        stop_words = 'english',\n",
    "        ngram_range = (1,ngram),\n",
    "        max_features = max_feature,\n",
    "    )\n",
    "\n",
    "# k 折交叉验证\n",
    "def k_evaluate(clf,x_train,y_train,x_test,k=10,n_est=0):\n",
    "    skf = StratifiedKFold(n_splits=k, random_state=7,shuffle=True) \n",
    "    test_preds = np.zeros((x_test.shape[0],1),int)\n",
    "    for KF_index,(train_index,valid_index) in enumerate(skf.split(x_train, train_df['label'].values)):\n",
    "        logging.info('第%d折交叉验证开始...'%(KF_index + 1))\n",
    "        # 训练集划分\n",
    "        x_train_,x_valid_ = x_train[train_index],x_train[valid_index]\n",
    "        y_train_,y_valid_ = y_train[train_index],y_train[valid_index]\n",
    "        # 开始训练...\n",
    "        clf.fit(x_train_,y_train_)\n",
    "        # 执行预测\n",
    "        val_pred = clf.predict(x_valid_)\n",
    "        logging.info('准确率为：%.7f'%f1_score(y_valid_,val_pred,average='macro'))\n",
    "        test_preds = np.column_stack((test_preds,clf.predict(x_test)))\n",
    "#         test_pred += clf.predict_proba(x_test)\n",
    "        logging.info('保存模型est%d_KF_index%d'%(n_est,KF_index + 1))\n",
    "        joblib.dump(clf,data_path + 'LGBM/model/est%d_KF_index%d'%(n_est,KF_index + 1),compress=3)\n",
    "    return test_preds\n",
    "\n",
    "def save_pred2file(saved_path,test_preds):\n",
    "    preds = []\n",
    "    for i,test_list in enumerate(test_preds):    \n",
    "        #  取预测数最多的作为预测结果   \n",
    "        preds.append(np.argmax(np.bincount(test_list)))\n",
    "    preds = np.array(preds)\n",
    "    submission = pd.DataFrame()\n",
    "    submission['label'] = preds\n",
    "    submission.to_csv(saved_path,index=False)\n",
    "    print(\"保存完毕\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "f3d783ae-33e1-4168-ae17-f86a02ae81e3"
   },
   "outputs": [],
   "source": [
    "# tfidf = define_tfidf(3,7000)\n",
    "# tfidf.fit(pd.concat([train_df['text'],test_df['text'],test_b_df['text']]))\n",
    "# joblib.dump(tfidf,data_path+'tfidf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "e5933498-8562-4f33-8807-4c960aa62d6d"
   },
   "outputs": [],
   "source": [
    "tfidf = joblib.load(data_path+'tfidf.model')\n",
    "train_features = tfidf.transform(train_df['text'])\n",
    "test_features = tfidf.transform(test_df['text'])\n",
    "# test_b_features = tfidf.transform(test_b_df['text'])\n",
    "\n",
    "x_train = train_features\n",
    "y_train = train_df['label']\n",
    "x_test = test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "d4d1f0af-30bb-4e26-a9e2-ef7d64708688"
   },
   "source": [
    "## LGBM 调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "4f7df1d2-f002-4538-9613-2375faab8499"
   },
   "source": [
    "## 多线程运行 k 折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "80fe0807-37d0-4cb6-8877-af06b72e0c06"
   },
   "outputs": [],
   "source": [
    "class TFIDF_based:\n",
    "    def __init__(self, X_train, Y_train, X_test, varified_parament, param_value):\n",
    "        self.x_train = X_train\n",
    "        self.y_train = Y_train\n",
    "        self.x_test = X_test\n",
    "        self.varified_param = varified_parament\n",
    "        self.param_value = param_value\n",
    "        self.test_preds = np.zeros((X_test.shape[0], 1), int)\n",
    "        self.threads = []\n",
    "\n",
    "    # k 折交叉验证\n",
    "    def k_evaluate(self, clf, k=5):\n",
    "        skf = StratifiedKFold(n_splits=k, random_state=7, shuffle=True)\n",
    "\n",
    "        for KF_index, (train_index, valid_index) in enumerate(skf.split(self.x_train, self.y_train.values)):\n",
    "            logging.info('第%d折交叉验证开始...' % (KF_index + 1))\n",
    "            # 训练集划分\n",
    "            x_train_, x_valid_ = self.x_train[train_index], self.x_train[valid_index]\n",
    "            y_train_, y_valid_ = self.y_train[train_index], self.y_train[valid_index]\n",
    "            # 将函数加入多线程列表中\n",
    "            self.threads.append(Thread(target=self.train, args=(clf, x_train_, y_train_, x_valid_, y_valid_, KF_index)))\n",
    "\n",
    "    def train(self, clf, x_train, y_train, x_valid, y_valid, KF_index):\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        # 在验证集上判断模型的准确率\n",
    "        val_pred = clf.predict(x_valid)\n",
    "        logging.info('准确率为：%.7f' % f1_score(y_valid, val_pred, average='macro'))\n",
    "\n",
    "        self.test_preds = np.column_stack((self.test_preds, clf.predict(self.x_test)))\n",
    "\n",
    "        model_name = '%s%.3f_KF_index%d' % (self.varified_param, self.param_value, KF_index + 1)\n",
    "        logging.info('保存模型:'+ model_name)\n",
    "        joblib.dump(clf, './download/LGBM/model/' + model_name + '.model', compress=3)\n",
    "\n",
    "    def save_pred2file(self, saved_path):\n",
    "        preds = []\n",
    "        for i, test_list in enumerate(self.test_preds):\n",
    "            #  取预测数最多的作为预测结果\n",
    "            preds.append(np.argmax(np.bincount(test_list)))\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        # 转为 CSV 文件\n",
    "        submission = pd.DataFrame()\n",
    "        submission['label'] = preds\n",
    "        submission.to_csv(saved_path, index=False)\n",
    "        logging.info('预测数据保存到csv文件')\n",
    "        logging.info('*' * 20)\n",
    "\n",
    "    def run(self, clf, saved_path):\n",
    "        self.k_evaluate(clf)\n",
    "        for t in self.threads:\n",
    "            t.setDaemon(True)\n",
    "            t.start()\n",
    "        for t in self.threads:\n",
    "            t.join()\n",
    "        self.save_pred2file(saved_path)\n",
    "        self.test_preds = np.zeros((self.x_test.shape[0], 1), int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "0efdc268-e205-4b3a-ba65-27973d54c8ba"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        #     'bagging_fraction':0.8,\n",
    "#         'learning_rate': 0.1,\n",
    "        'objective': 'multiclass',\n",
    "        'n_estimators': 500,\n",
    "        'num_classes': 14,\n",
    "        'reg_alpha': 0.001,\n",
    "        'reg_lambda': 0.01\n",
    "    }\n",
    "# baseline，默认配置 0.943 左右\n",
    "# 1、n_estimators-500:决策树棵数 —— 0.946\n",
    "# 2、learning_rate:\n",
    "# for param_value in range(550, 601, 50):\n",
    "param_value = 0.01\n",
    "varified_param = 'learning_rate'\n",
    "information = '%s:%.3f 验证中...'%(varified_param,param_value)\n",
    "logging.info(information)\n",
    "print(infomation)\n",
    "params[varified_param] = param_value\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "lgbm = TFIDF_based(x_train, y_train, x_test, varified_param, param_value)\n",
    "lgbm.run(clf, data_path + 'LGBM/Test_a_results/%s_%.3f.csv' % (varified_param, param_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "60127cee-c6c5-45c9-92b8-9310d99416ed"
   },
   "source": [
    "### 日志：经过测试，将训练和预测更改为多线程的方式可以提升效率，n_estimators为250时，时间减少了50分钟左右，为400以上时，可以减少一个小时以上的时间，经过考量，n_estimators 选择了一个相对折中的值——500，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "110239bb-5c1d-45de-9e9e-a3ff132d1cfd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
